{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOGDa9iEXJ8zEcAc5EUFc5g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import cv2\n","import mediapipe as mp\n","import  cv2\n","import matplotlib.pyplot as plt\n","\n","# Step 1: Create VideoCapture object to read the input video\n","input_video_path = r\"/content/task_4_video.mp4\"\n","cap = cv2.VideoCapture(input_video_path)\n","\n","# Step 2: Define output video parameters\n","output_video_path = r\"/content/task_4_output.mp4\"\n","output_fps = cap.get(cv2.CAP_PROP_FPS)\n","output_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","\n","# Step 3: Create VideoWriter object to write the output video\n","fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n","out = cv2.VideoWriter(output_video_path, fourcc, output_fps, output_size)\n","\n","# Step 4: Create a mediapipe pose instance\n","mp_pose = mp.solutions.pose.Pose()\n","\n","# Step 5: Process each frame of the input video\n","while cap.isOpened():\n","    # Read a frame\n","    ret, frame = cap.read()\n","\n","    if not ret:\n","        break\n","\n","    # Convert the frame to RGB\n","    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","    # Process the frame with mediapipe pose estimation\n","    results = mp_pose.process(frame_rgb)\n","\n","    # Draw the pose skeleton on the frame\n","    mp.solutions.drawing_utils.draw_landmarks(frame, results.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)\n","\n","    # Write the frame to the output video\n","    out.write(frame)\n","\n","  # Display the frame\n","    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n","    plt.axis('off')\n","    plt.show()\n","    \n","    # Exit loop if 'q' is pressed\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","# Step 6: Release the VideoCapture and VideoWriter objects\n","cap.release()\n","out.release()\n","\n","# Step 7: Close all windows\n","cv2.destroyAllWindows()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1afB1LmA_5nSV-ZR1r1-UcSOzK3xAKwi9"},"id":"5ZZJPlTnXolZ","executionInfo":{"status":"error","timestamp":1684506424445,"user_tz":-330,"elapsed":15002,"user":{"displayName":"shubham gokhale","userId":"14583170370013432237"}},"outputId":"a777bedc-6524-4ecb-d499-59a504a1acfb"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["import cv2\n","import mediapipe as mp\n","import matplotlib.pyplot as plt\n","\n","# Step 1: Create VideoCapture object to read the input video\n","input_video_path = \"/content/task_4_video.mp4\"\n","cap = cv2.VideoCapture(input_video_path)\n","\n","# Step 2: Define output video parameters\n","output_video_path = \"/content/task_4_video.mp4\"\n","output_fps = cap.get(cv2.CAP_PROP_FPS)\n","output_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","\n","# Step 3: Create VideoWriter object to write the output video\n","fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n","out = cv2.VideoWriter(output_video_path, fourcc, output_fps, output_size)\n","\n","# Step 4: Create a mediapipe pose instance\n","mp_pose = mp.solutions.pose.Pose()\n","\n","# Step 5: Process each frame of the input video\n","while cap.isOpened():\n","    # Read a frame\n","    ret, frame = cap.read()\n","\n","    if not ret:\n","        break\n","\n","    # Convert the frame to RGB\n","    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","    # Process the frame with mediapipe pose estimation\n","    results = mp_pose.process(frame_rgb)\n","\n","    # Draw the pose landmarks on the frame\n","    mp.solutions.drawing_utils.draw_landmarks(frame, results.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)\n","\n","    # Write the frame to the output video\n","    out.write(frame)\n","\n","    # Display the frame\n","    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n","    plt.axis('off')\n","    plt.show()\n","\n","    # Exit loop if 'q' is pressed\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","# Step 6: Release the VideoCapture and VideoWriter objects\n","cap.release()\n","out.release()\n","\n","# Step 7: Close all windows\n","cv2.destroyAllWindows()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1kvl5odv6gC3btWMR7QFfnCcynzLIrPha"},"id":"-rm4ceOzXpD1","executionInfo":{"status":"error","timestamp":1684506463504,"user_tz":-330,"elapsed":9923,"user":{"displayName":"shubham gokhale","userId":"14583170370013432237"}},"outputId":"d98d226b-b299-4eb7-87a2-50721db7a896"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"6d-ze9Y6n4mu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"k_o2axJkYpta","executionInfo":{"status":"ok","timestamp":1684509196744,"user_tz":-330,"elapsed":615,"user":{"displayName":"shubham gokhale","userId":"14583170370013432237"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import mediapipe as mp\n","import matplotlib.pyplot as plt\n","\n","\n","# Step 1: Create VideoCapture object to read the input video\n","input_video_path = \"/content/task_4_video.mp4\"\n","cap = cv2.VideoCapture(input_video_path)\n","\n","# Step 2: Set the buffer size to 10 seconds\n","buffer_size = 10  # In seconds\n","cap.set(cv2.CAP_PROP_BUFFERSIZE, buffer_size * cap.get(cv2.CAP_PROP_FPS))\n","\n","# Step 3: Define output video parameters\n","output_video_path = \"/content/task_4_output.mp4\"\n","output_fps = cap.get(cv2.CAP_PROP_FPS)\n","output_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","\n","# Step 4: Create VideoWriter object to write the output video\n","fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n","out = cv2.VideoWriter(output_video_path, fourcc, output_fps, output_size)\n","\n","# Step 5: Create a mediapipe pose instance\n","mp_pose = mp.solutions.pose.Pose()\n","\n","# Step 6: Process each frame of the input video\n","while cap.isOpened():\n","    # Read a frame\n","    ret, frame = cap.read()\n","\n","    if not ret:\n","        break\n","\n","    # Convert the frame to RGB\n","    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","    # Process the frame with mediapipe pose estimation\n","    results = mp_pose.process(frame_rgb)\n","\n","    # Draw the pose landmarks on the frame\n","    mp.solutions.drawing_utils.draw_landmarks(frame, results.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)\n","\n","    # Convert the frame back to BGR before writing to the output video\n","    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n","\n","    # Write the frame to the output video\n","    out.write(frame_bgr)\n","  # Display the frame\n","    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n","    plt.axis('off')\n","    plt.show()\n","\n","    # Exit loop if 'q' is pressed\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","# Step 7: Release the VideoCapture and VideoWriter objects\n","cap.release()\n","out.release()\n","\n","# Step 8: Close all windows\n","cv2.destroyAllWindows()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Pq76eXKk9XUSrPwu-vR17E8WDvjhGQ2C"},"id":"GnpgCluXn6gq","executionInfo":{"status":"ok","timestamp":1684510298347,"user_tz":-330,"elapsed":161114,"user":{"displayName":"shubham gokhale","userId":"14583170370013432237"}},"outputId":"6f114603-b9e0-4c92-fa9c-a08db5e0c4dd"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":[],"metadata":{"id":"ZC3z8ns5pfHq"}},{"cell_type":"code","source":[],"metadata":{"id":"j9Uf5e35oNS8"},"execution_count":null,"outputs":[]}]}